{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 第四章 前馈神经网络\n",
    "\n",
    "### 1、在课堂中我们学习了Logistic激活函数的前向和反向求解过程。接下来，请动手实现 LeakyReLU 激活函数的算子，支持前向计算和反向的梯度计算，并与Paddle API实现结果对比，验证实现的准确性。<span style=\"color:red\">(必修题)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "from nndl.op import Op\r\n",
    "\r\n",
    "paddle.seed(10)\r\n",
    "\r\n",
    "class myLeakyReLU(Op): \r\n",
    "    def __init__(self, alpha=0.01):\r\n",
    "        super(Op).__init__()\r\n",
    "        self.alpha = alpha\r\n",
    "        self.outputs = None\r\n",
    "\r\n",
    "    def __call__(self, X):\r\n",
    "        return self.forward(X)\r\n",
    "\r\n",
    "    def forward(self, inputs):\r\n",
    "        a1 = (paddle.cast((inputs > 0), dtype='float32') * inputs)\r\n",
    "        a2 = (paddle.cast((inputs <= 0), dtype='float32') * (self.alpha * inputs))\r\n",
    "        self.outputs = a1 + a2\r\n",
    "        return self.outputs\r\n",
    "\r\n",
    "    def backward(self, grads):\r\n",
    "        part_1 = (paddle.cast((self.outputs > 0), dtype='float32') * 1)\r\n",
    "        part_2 = (paddle.cast((self.outputs <= 0), dtype='float32') * self.alpha)\r\n",
    "        outputs_grad_inputs = part_1 + part_2\r\n",
    "        return paddle.multiply(grads, outputs_grad_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0726 20:25:47.325665 12459 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 10.1\n",
      "W0726 20:25:47.330221 12459 gpu_resources.cc:91] device: 0, cuDNN Version: 7.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[5, 4], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[0.00022478, 0.85032451, 0.01352605, 0.91611278],\n",
      "        [0.67955703, 0.89689773, 0.14975823, 0.98008388],\n",
      "        [0.62906164, 0.43512452, 0.89547771, 0.60389930],\n",
      "        [0.82229692, 0.09566654, 0.91918784, 0.11712553],\n",
      "        [0.76633900, 0.95084548, 0.26211733, 0.66611362]])\n"
     ]
    }
   ],
   "source": [
    "x = paddle.rand([5,4])\r\n",
    "\r\n",
    "my_leakyrelu = myLeakyReLU(alpha=0.5)\r\n",
    "cal_y_1 = my_leakyrelu(x)\r\n",
    "print(cal_y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[5, 4], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[0.00022478, 0.85032451, 0.01352605, 0.91611278],\n",
      "        [0.67955703, 0.89689773, 0.14975823, 0.98008388],\n",
      "        [0.62906164, 0.43512452, 0.89547771, 0.60389930],\n",
      "        [0.82229692, 0.09566654, 0.91918784, 0.11712553],\n",
      "        [0.76633900, 0.95084548, 0.26211733, 0.66611362]])\n",
      "None\n",
      "Tensor(shape=[5, 4], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[0.00022478, 0.85032451, 0.01352605, 0.91611278],\n",
      "        [0.67955703, 0.89689773, 0.14975823, 0.98008388],\n",
      "        [0.62906164, 0.43512452, 0.89547771, 0.60389930],\n",
      "        [0.82229692, 0.09566654, 0.91918784, 0.11712553],\n",
      "        [0.76633900, 0.95084548, 0.26211733, 0.66611362]])\n"
     ]
    }
   ],
   "source": [
    "paddle_leakyrelu = paddle.nn.LeakyReLU(negative_slope=0.5)\r\n",
    "cal_y_2 = paddle_leakyrelu(x)\r\n",
    "print(cal_y_2)\r\n",
    "print(cal_y_2.backward())\r\n",
    "print(cal_y_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "可以看出实现的功能基本准确。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.在课程中，我们利用前馈神经网络解决了鸢尾花分类任务。那请尝试基于 MNIST 手写数字识别数据集，设计合适的前馈神经网络进行实验，并 取得 95% 以上的准确率，并统计参数量和计算量。<span style=\"color:red\">(附加题&加分题)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download training data and load training data\n",
      "load finished\n"
     ]
    }
   ],
   "source": [
    "from paddle.vision.transforms import Compose, Normalize\r\n",
    "\r\n",
    "transform = Compose([Normalize(mean=[127.5],\r\n",
    "                               std=[127.5],\r\n",
    "                               data_format='CHW')])\r\n",
    "# 使用transform对数据集做归一化\r\n",
    "print('download training data and load training data')\r\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)\r\n",
    "test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)\r\n",
    "print('load finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "import paddle.nn.functional as F\r\n",
    "class LinearNet(paddle.nn.Layer):\r\n",
    "    def __init__(self):\r\n",
    "        super(LinearNet, self).__init__()\r\n",
    "        self.linear1 = paddle.nn.Linear(in_features=28*28, out_features=1500)\r\n",
    "        self.linear2 = paddle.nn.Linear(in_features=1500, out_features=500)\r\n",
    "        self.linear3 = paddle.nn.Linear(in_features=500, out_features=10)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        batch_size = x.shape[0]\r\n",
    "        x = x.reshape([batch_size, -1])\r\n",
    "        x = self.linear1(x)\r\n",
    "        x = F.leaky_relu(x)\r\n",
    "        x = self.linear2(x)\r\n",
    "        x = F.leaky_relu(x)\r\n",
    "        x = self.linear3(x)\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddle.metric import Accuracy\r\n",
    "model = paddle.Model(LinearNet())   # 用Model封装模型\r\n",
    "optim = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())\r\n",
    "\r\n",
    "# 配置模型\r\n",
    "model.prepare(\r\n",
    "    optim,\r\n",
    "    paddle.nn.CrossEntropyLoss(),\r\n",
    "    Accuracy()\r\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/3\n",
      "step 938/938 [==============================] - loss: 0.2352 - acc: 0.9188 - 9ms/step         \n",
      "Epoch 2/3\n",
      "step 938/938 [==============================] - loss: 0.0649 - acc: 0.9598 - 9ms/step        \n",
      "Epoch 3/3\n",
      "step 938/938 [==============================] - loss: 0.0488 - acc: 0.9698 - 9ms/step         \n"
     ]
    }
   ],
   "source": [
    "# 训练模型\r\n",
    "model.fit(train_dataset,\r\n",
    "        epochs=3,\r\n",
    "        batch_size=64,\r\n",
    "        verbose=1\r\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "step 157/157 [==============================] - loss: 7.7291e-04 - acc: 0.9680 - 8ms/step     \n",
      "Eval samples: 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.0007729138], 'acc': 0.968}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      " Layer (type)       Input Shape          Output Shape         Param #    \n",
      "===========================================================================\n",
      "   Linear-1         [[64, 784]]           [64, 1500]         1,177,500   \n",
      "   Linear-2         [[64, 1500]]          [64, 500]           750,500    \n",
      "   Linear-3         [[64, 500]]            [64, 10]            5,010     \n",
      "===========================================================================\n",
      "Total params: 1,933,010\n",
      "Trainable params: 1,933,010\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 0.98\n",
      "Params size (MB): 7.37\n",
      "Estimated Total Size (MB): 8.55\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 1933010, 'trainable_params': 1933010}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "模型参数量为1933010."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###  3.小明搭建了一个10层的前馈神经网络，激活函数为ReLU，学习率为2.0，但是发现模型不收敛，可能是什么原因？请帮忙分析。<span style=\"color:red\">(附加题&简答题&加分题)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "+ 可能是**死亡ReLU问题**造成的，学习率过大会造成更新权重时，权重更新过多，一直小于0，总得不到更新。\n",
    "\n",
    "+ 网络可能过深，参数无法得到充分的学习。\n",
    "\n",
    "+ 解决方法：适当调整网络结构，调整学习率和优化器，也可以换成如LeakyReLU、PReLU等改进的激活函数。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
